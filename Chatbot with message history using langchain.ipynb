{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9385150-aefd-49ca-819f-1f8c73311b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1c2e32-e2ea-4c52-9723-9d5a6cb3d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0ec02d-b4d1-47b7-88b5-7762d4e31bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002516C70F610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002516C6FF940>, model_name='gemma2-9b-it', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model='Llama3-8b-8192',groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b446de-a99a-4d84-8875-642c799561c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Pratik! \\n\\nIt's nice to meet you. \\n\\nDH stands for a lot of things - could you tell me what field you work in?  Knowing that will help me understand your context better and maybe even have a more relevant conversation with you. \\n\\nFor example, are you in:\\n\\n* **Digital Health?**\\n* **Data Handling?**\\n* **Distribution Hubs?**\\n* **Something else entirely?** \\n\\n\\nLet me know! ðŸ˜Š\\n\", response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 26, 'total_tokens': 130, 'completion_time': 0.21416199, 'prompt_time': 0.00264524, 'queue_time': None, 'total_time': 0.21680723}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4675c498-03c6-49ac-916a-11bc4ccd5326-0', usage_metadata={'input_tokens': 26, 'output_tokens': 104, 'total_tokens': 130})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"Hello My name is Pratik and I am working in DH\")])\n",
    "# this info is going to model and we will get the ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ab0eef-6c95-4353-95a4-cb89cfcb222e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Pratik and you work in DH. \\n\\nIs there anything else you'd like to tell me about your work in DH? ðŸ˜Š \\n\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 146, 'total_tokens': 183, 'completion_time': 0.077000949, 'prompt_time': 0.007630499, 'queue_time': None, 'total_time': 0.084631448}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-aaa1ad50-cd5f-45a0-9220-84d60fdb2e80-0', usage_metadata={'input_tokens': 146, 'output_tokens': 37, 'total_tokens': 183})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "        HumanMessage(content=\"Hello My name is Pratik and I am working in DH\"),\n",
    "        AIMessage (content=\"Hello Pratik! \\n\\nIt's nice to meet you. \\n\\nDH stands for a lot of things - could you tell me what field you work in?  Knowing that will help me understand your context better and maybe even have a more relevant conversation with you. \\n\\nFor example, are you in:\\n\\n* **Digital Health?**\\n* **Data Handling?**\\n* **Distribution Hubs?**\\n* **Something else entirely?** \\n\\n\\nLet me know! ðŸ˜Š\\n\"),\n",
    "        HumanMessage(content=\"Hey whats my name and where I work\")\n",
    "])\n",
    "# this is just eg where LLM model is able to remember things or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c871b49-c25a-402e-bfb4-d57b5369b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3ef158-20ac-4ea7-8718-46f9c0b74cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method will create different session and will remember the message w.r.t session\n",
    "#when we call this method it will check if session id os present or not if present will return the session id with message history\n",
    "# this session_id will help to distinguish from 1 session to another seesion\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db3c92e-8e74-4758-a770-1fb2652241e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'configurable':{'session_id':'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ecfe52c-916d-4479-9212-19e10665e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on session_id = chat1 it will remember below all message history\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello My name is Pratik and I am working in DH\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48b6909-3252-4751-9dcd-ed08980d8e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Pratik! \\n\\nIt's nice to meet you.  \\n\\nDH stands for quite a few things. Could you tell me what industry or field DH stands for in your case? \\n\\nKnowing that will help me understand your work better and perhaps have a more relevant conversation with you. ðŸ˜Š  \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f59b065-4a7e-4ebe-8e4d-76734a9076e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Pratik. ðŸ˜Š  \\n\\nI remember that from our earlier conversation. \\n\\n\\n\\nLet me know if there's anything else I can help you with!  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 189, 'total_tokens': 228, 'completion_time': 0.078335573, 'prompt_time': 0.016789078, 'queue_time': None, 'total_time': 0.095124651}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1e46ee51-9782-4e22-87c5-45125e21d1ac-0', usage_metadata={'input_tokens': 189, 'output_tokens': 39, 'total_tokens': 228})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so this will give answer because we have given the same session id where we fed the info to that specific session\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f8df085-640d-44c3-a4b0-d1da1b0b770e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! ðŸ˜Š\\n\", response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 18, 'total_tokens': 58, 'completion_time': 0.080836348, 'prompt_time': 0.002321174, 'queue_time': None, 'total_time': 0.083157522}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-48b74172-1893-42e1-9c08-3d4b0b9191f8-0', usage_metadata={'input_tokens': 18, 'output_tokens': 40, 'total_tokens': 58})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={'configurable':{'session_id':'chat2'}}\n",
    "# so this will give no answer because we have not  fed the info to that specific session 'session_id':'chat2'\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "118a3d70-f011-46ce-8e18-ed2b0bf80749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on session_id = chat1 it will remember below all message history\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello My name is Abhishek and I work in DH\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e6dfa1-50b6-460f-8719-ea7cb686967e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Abhishek.  \\n\\nI remember from our previous conversation!  ðŸ˜Š \\n\\n\\n\\n', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 136, 'total_tokens': 157, 'completion_time': 0.042, 'prompt_time': 0.008751043, 'queue_time': None, 'total_time': 0.050751043}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f76c96c8-1ab4-49bc-bacb-4964a53667f5-0', usage_metadata={'input_tokens': 136, 'output_tokens': 21, 'total_tokens': 157})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61530c1-4933-4a1f-be47-0ffb116e363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You mentioned you work in DH, but didn't specify which company.  \\n\\nDo you want to tell me?  I'm curious!  ðŸ˜Š  \\n\", response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 167, 'total_tokens': 203, 'completion_time': 0.072753871, 'prompt_time': 0.007919157, 'queue_time': None, 'total_time': 0.080673028}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5221200-250f-4eee-85df-d8b93d73057a-0', usage_metadata={'input_tokens': 167, 'output_tokens': 36, 'total_tokens': 203})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Where I work\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141e52d-9d53-4acf-8319-d0fd07abe936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so based on ur chat seesion it will remember the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c530601-aec5-433b-832b-b985db1ed511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fca22-23f2-4ca7-9359-f33ede52c154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
